task: Isaac-Velocity-Rough-Unitree-Go1-v0  # Name of the task.  `Isaac-Velocity-Rough-Unitree-Go1-v0` `Isaac-Velocity-Flat-Unitree-Go1-v0`
seed: 1 # TODO: Performance should be somewhat consistent across seeds but pls verify
max_iterations: 1500  # TODO: Adjust this to train for longer: 1.5k should give you a working policy for rough terrain
distributed: False  # Whether to use distributed training.
video: false  # Record videos during training.
video_length: 10  # Length of the recorded video (in steps).
video_interval: 10  # Interval between video recordings (in steps).
headless: true
# enable_cameras: false

#experiment_name: EXPERIMENT_NAME  # Name of the experiment folder where logs will be stored.
#run_name: RUN_NAME   # Run name suffix to the log directory.
resume: false  # Whether to resume from a checkpoint.
#load_run: LOAD_RUN   # Name of the run folder to resume from.
#checkpoint: CHECKPOINT  # Checkpoint file to resume from.
logger: wandb  # Logger module to use. {neptune, wandb, tensorboard}
log_project_name: MRSS25  # Name of the logging project when using wandb or neptune.

env:
  scene:
    num_envs: 4096  # Number of environments to generate terrain for and run in parallel. TODO: Adjust this to your machine. More robot means faster training, fewer robots means less VRAM usage.
    terrain:
      max_init_terrain_level: 5
      physics_material:
        compliant_contact_damping: 0.0
        compliant_contact_stiffness: 0.0
        dynamic_friction: 1.0
        friction_combine_mode: 'multiply'
        improve_patch_friction: True
        restitution: 0.0
        restitution_combine_mode: 'multiply'
        static_friction: 1.0
      terrain_generator:
        border_height: 1.0
        border_width: 20.0
        cache_dir: '/tmp/isaaclab/terrains'
        curriculum: True
        difficulty_range: [ 0.0, 1.0 ]
        horizontal_scale: 0.1
        num_cols: 20
        num_rows: 10
        size: [ 8.0, 8.0 ]
        slope_threshold: 0.75
        use_cache: False
        vertical_scale: 0.005
  rewards: # TODO: Play with these
    action_rate_l2:
      weight: -0.1
    ang_vel_xy_l2:
      weight: -0.05
    dof_acc_l2:
      weight: -2.5e-07
    dof_pos_limits:
      weight: 0.0
    dof_torques_l2:
      weight: -0.0002
    feet_air_time:
      weight: 0.01
    flat_orientation_l2:
      weight: 0.0
    lin_vel_z_l2:
      weight: -2.0
    track_ang_vel_z_exp:
      weight: 0.75
    track_lin_vel_xy_exp:
      weight: 1.5
  events: # TODO: Play with these
    add_base_mass:
      params:
        mass_distribution_params: [ -1.0, 3.0 ]  # Range for randomizing the base mass
    base_external_force_torque:
      params:
        force_range: [ 0.0, 0.0 ]  # Range for randomizing the external force applied to the base
        torque_range: [ 0.0, 0.0 ]  # Range for randomizing the external torque applied to the base

algorithm:
  class_name: 'PPO'
  clip_param: 0.2
  desired_kl: 0.01
  entropy_coef: 0.01
  gamma: 0.99
  lam: 0.95
  learning_rate: 0.001
  max_grad_norm: 1.0
  normalize_advantage_per_mini_batch: False
  num_learning_epochs: 5
  num_mini_batches: 4
  rnd_cfg: null
  schedule: 'adaptive'
  symmetry_cfg: null
  use_clipped_value_loss: True
  value_loss_coef: 1.0
